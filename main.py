import os, shutil, subprocess, base64, io
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional
from fpdf import FPDF
from openai import OpenAI
import sendgrid
from sendgrid.helpers.mail import Mail, Attachment, FileContent, FileName, FileType, Disposition

# === App Setup ===
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SENDGRID_API_KEY = os.getenv("SENDGRID_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

UPLOAD_DIR = "/tmp/uploads"
FASTSURFER_INPUT = os.path.expanduser("~/fastsurfer-input")
FASTSURFER_OUTPUT = os.path.expanduser("~/fastsurfer-output")
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(FASTSURFER_INPUT, exist_ok=True)
os.makedirs(FASTSURFER_OUTPUT, exist_ok=True)

# === Save NIfTI + Print Docker command for FastSurfer ===
def run_fastsurfer(nifti_path: str, subject_id: str):
    input_path = os.path.join(FASTSURFER_INPUT, f"{subject_id}_T1w.nii.gz")
    shutil.copy(nifti_path, input_path)
    print(f"üß† Copied MRI to: {input_path}")
    print("‚ö†Ô∏è NOW RUN THIS IN TERMINAL:")
    print(f"""
docker run --rm --gpus all --user root \\
  -v {FASTSURFER_INPUT}:/data:ro \\
  -v {FASTSURFER_OUTPUT}:/output \\
  -e SUBJECTS_DIR=/output \\
  deepmi/fastsurfer:cu124-v2.3.3 \\
  --t1 /data/{subject_id}_T1w.nii.gz \\
  --sid {subject_id} \\
  --sd /output \\
  --parallel --seg_only --allow_root
    """)

# === Extract biomarkers from FastSurfer stats ===
def parse_stats(subject_id):
    stats_dir = os.path.join(FASTSURFER_OUTPUT, subject_id, "stats")
    aseg = os.path.join(stats_dir, "aseg+DKT.stats")
    aparc = os.path.join(stats_dir, "lh.aparc.stats")

    metrics, thickness = {}, []
    if os.path.exists(aseg):
        with open(aseg) as f:
            for line in f:
                if line.startswith("#"): continue
                parts = line.split()
                if len(parts) < 5: continue
                label = parts[4]
                try: volume = float(parts[3])
                except: continue
                metrics[label] = volume

    if os.path.exists(aparc):
        with open(aparc) as f:
            for line in f:
                if line.startswith("#"): continue
                parts = line.split()
                if len(parts) >= 6:
                    try: thickness.append(float(parts[5]))
                    except: continue

    lh = metrics.get("Left-Hippocampus", 0)
    rh = metrics.get("Right-Hippocampus", 0)
    lv = metrics.get("Left-Lateral-Ventricle", 0)
    rv = metrics.get("Right-Lateral-Ventricle", 0)
    wm_left = metrics.get("Left-Cerebral-White-Matter")
    wm_right = metrics.get("Right-Cerebral-White-Matter")
    ctx_left = metrics.get("ctx-lh")
    ctx_right = metrics.get("ctx-rh")

    return {
        "Left Hippocampus": lh,
        "Right Hippocampus": rh,
        "Asymmetry Index": round(abs(lh - rh) / max(lh, rh + 1e-6), 2),
        "Evans Index": round((lv + rv) / (lh + rh + 1e-6), 2),
        "Left WM Volume": wm_left,
        "Right WM Volume": wm_right,
        "Left Cortex Volume": ctx_left,
        "Right Cortex Volume": ctx_right,
        "Average Cortical Thickness": round(sum(thickness)/len(thickness), 2) if thickness else None
    }

# === Disease stage logic ===
def predict_stage(mmse, cdr, adas):
    if cdr >= 1 or mmse < 21 or adas > 35:
        return "Alzheimer's"
    elif 0.5 <= cdr < 1 or 21 <= mmse < 26:
        return "MCI"
    elif cdr == 0 and mmse >= 26:
        return "Normal"
    return "Uncertain"

# === GPT clinical summary ===
def generate_summary(biomarkers, mmse, cdr, adas):
    prompt = f"""Patient MRI & cognitive results:
- Left Hippocampus: {biomarkers['Left Hippocampus']} mm¬≥
- Right Hippocampus: {biomarkers['Right Hippocampus']} mm¬≥
- Asymmetry Index: {biomarkers['Asymmetry Index']}
- Evans Index: {biomarkers['Evans Index']}
- Cortical Thickness: {biomarkers['Average Cortical Thickness']} mm
- MMSE: {mmse}, CDR: {cdr}, ADAS-Cog: {adas}

Generate:
- Clinical interpretation
- Cognitive decline explanation
- Alzheimer's stage
- Next steps and recommendations
- Markdown format"""
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=1600
    )
    return response.choices[0].message.content.strip()

# === Create PDF report ===
def create_pdf(summary_text):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size=12)
    for line in summary_text.split("\n"):
        pdf.multi_cell(0, 10, line)
    pdf_output = io.BytesIO()
    pdf.output(pdf_output)
    return pdf_output.getvalue()

# === Email PDF + segmentation preview ===
def send_email_report(email, pdf_bytes, segmentation_b64):
    sg = sendgrid.SendGridAPIClient(SENDGRID_API_KEY)
    attachment = Attachment(
        FileContent(base64.b64encode(pdf_bytes).decode()),
        FileName("report.pdf"),
        FileType("application/pdf"),
        Disposition("attachment")
    )
    html_content = f"""
    <p>Hi,</p>
    <p>Your MRI report is ready. See attached PDF.</p>
    <p><img src="data:image/png;base64,{segmentation_b64}" width="400"/></p>
    <p>Stay healthy,<br>Alzheimer's Risk Platform</p>
    """
    message = Mail(
        from_email="noreply@alzapi.com",
        to_emails=email,
        subject="üß† Your Alzheimer's MRI Report",
        html_content=html_content
    )
    message.attachment = attachment
    sg.send(message)

# === Step 1: Upload MRI, wait for manual FastSurfer ===
@app.post("/analyze-mri/")
async def analyze_mri(file: UploadFile = File(...),
                      mmse: int = Form(...),
                      cdr: float = Form(...),
                      adas_cog: float = Form(...),
                      email: str = Form(...)):
    subject_id = "sub-01"
    nifti_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(nifti_path, "wb") as f:
        shutil.copyfileobj(file.file, f)

    run_fastsurfer(nifti_path, subject_id)
    return {"message": "üì§ MRI uploaded. Run FastSurfer manually on your machine."}

# === Step 2: Finish analysis from stats after local Docker ===
@app.post("/analyze-from-stats/")
async def analyze_after_local_docker(mmse: int = Form(...),
                                     cdr: float = Form(...),
                                     adas_cog: float = Form(...),
                                     email: str = Form(...)):
    subject_id = "sub-01"
    biomarkers = parse_stats(subject_id)
    stage = predict_stage(mmse, cdr, adas_cog)
    summary = generate_summary(biomarkers, mmse, cdr, adas_cog)
    pdf = create_pdf(summary)

    seg_path = os.path.join(FASTSURFER_OUTPUT, subject_id, "mri", "aparc+aseg.png")
    with open(seg_path, "rb") as f:
        seg_base64 = base64.b64encode(f.read()).decode()

    send_email_report(email, pdf, seg_base64)

    return {
        "üß† Clinical Biomarkers": biomarkers,
        "üìà Cognitive Scores": {"MMSE": mmse, "CDR": cdr, "ADAS-Cog": adas_cog},
        "üß¨ Disease Stage": stage,
        "üìã GPT Summary": summary,
        "üßæ PDF Report": "‚úÖ Sent to email",
        "üß† Brain Segmentation Preview (base64)": seg_base64
    }

# === Optional: For cognitive test only ===
class ScoreInput(BaseModel):
    patient_name: str
    patient_email: str
    mmse: int
    cdr: float

@app.post("/analyze-cognitive-score/")
def analyze_score(input: ScoreInput):
    mmse, cdr = input.mmse, input.cdr
    adas_cog = 25  # placeholder
    stage = predict_stage(mmse, cdr, adas_cog)
    summary = generate_summary({}, mmse, cdr, adas_cog)
    return {"stage": stage, "report": summary}

@app.get("/")
def root():
    return {"message": "‚úÖ MRI + FastSurfer + GPT summary + Email working"}
